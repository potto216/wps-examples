# Designing a Modular Wireless Packet Analysis System
## Introduction

Designing a system to analyze wireless network captures at scale involves multiple components working together. We need to ingest daily Wireshark packet captures (in JSON format) of Bluetooth (initially) and potentially other protocols (IEEE 802.15.4, Wi-Fi), enrich them with GPS location data, and store everything efficiently for analysis. The system must scale to hundreds of millions of packet records while remaining modular and extensible. Key modules will include:

* Data Ingestion & Integration: Reading JSON packet captures (100MB per day) and linking each packet with GPS coordinates by timestamp.

* Scalable Data Storage: Choosing a database capable of handling time-indexed data on the order of 10^8 records, with fields for packet contents, timestamps, device info, location, spectrum/channel info, etc.

* Analysis Engine (ML/Stats): Batch analysis pipelines using machine learning and statistical methods (e.g. anomaly detection, device classification, time-series forecasting) to find patterns or outliers in the data.

* LLM-Guided Anomaly Detection: An orchestration layer where a Large Language Model (LLM) can interpret high-level analysis goals (possibly informed by wireless protocol standards) and generate queries or code to direct the analysis. The LLM will also summarize findings in natural language. Python will serve as the “glue” language connecting all these components.

This modular design ensures each part can be developed and improved independently. For example, we can start with Bluetooth-specific parsing/analysis and later add modules for Zigbee (802.15.4) or Wi-Fi without disrupting the whole system. Below, we discuss each component in detail, including technology options and best practices, to meet the requirements outlined.

# Data Ingestion and GPS Integration

Ingestion of Packet Captures: The capture files (around 100 MB JSON per session, ingested daily) will be processed by a Python-based ingestion module. Wireshark’s output (as JSON via TShark) contains nested protocol fields. Each packet JSON includes timestamp (frame.time_epoch), protocol identifiers, and detailed subfields (e.g. Bluetooth Low Energy advertising addresses, signal strength in btle_rf.signal_dbm, etc.). The ingestion module should parse these JSON records (using Python’s json library or streaming libraries) in a streaming/batch manner to handle large files without exhausting memory. Tools like PyShark (a Python wrapper for TShark) could directly capture and yield packet data, but since we already have JSON, simple parsing is sufficient. Key fields (timestamp, protocol type, addresses, RSSI, etc.) will be extracted for indexing, while the full JSON can be retained for completeness (perhaps stored as a blob or nested fields in a document store).

GPS Data Linking: We will enrich each packet with location data by correlating packet timestamps with GPS logs (from KML/GPX files). A GPS file provides a time-stamped route (latitude, longitude, etc.), and we can interpolate the device’s position for any packet’s timestamp. The ingestion module will:

1. Parse the KML/GPX file (using libraries like fastkml or gpxpy in Python) to obtain a sequence of (time, lat, lon) points.

1. For each packet’s timestamp, find the nearest GPS timestamps and interpolate to estimate the latitude/longitude at capture time. This interpolation accounts for the fact that GPS may log at, say, 1-second intervals while packets may arrive in between.

1. Attach the derived lat, lon (and possibly altitude or velocity, if needed) to the packet record’s metadata.

Additional Metadata: Besides location, the system will tag each packet with other metadata for analysis context: device info, capture context, and spectrum details. For example:

* Device info: This can include an identifier of the capturing device (if multiple sensors are used) and any known info about the observed devices. In Bluetooth, the advertising address (e.g. btle.advertising_address) could be logged; we might also resolve the OUI (first 3 bytes of MAC) to a manufacturer name for device-type inference. For Wi-Fi, device info might be MAC addresses of APs or clients, and for 802.15.4, device network IDs, etc.

* Capture session info: a session ID or the start/end time range of the capture, which helps group packets by session (given one JSON file per day). Also store the capture timestamp (frame.time) and perhaps the timezone or offset.

* Spectrum/channel info: The radio frequency or channel used. In the example, btle_rf.channel and flags indicate the BLE advertising channel and whether the packet was decrypted, etc. For Wi-Fi, we would capture the channel or frequency (2.4GHz vs 5GHz, etc.), and for 802.15.4, the channel or PAN ID. If the capturing hardware provides spectrum data (noise floor, etc.), that too can be recorded.

All these metadata ensure that analysis can filter or aggregate packets by location, device, channel, etc., enabling richer queries (e.g., “find anomalies only when device X was on channel Y with RSSI above -50 dBm”).

Batch Processing Consideration: Since ingestion is daily (no real-time requirement), we can afford to do this linking and parsing in batch. A scheduled Python script or ETL pipeline will run once per day, parse the JSON, merge GPS data, and then insert the enriched records into the database. This could be orchestrated with a simple cron job or a workflow tool if needed. Given ~100 MB JSON input, this process is manageable on a single machine (tens or hundreds of thousands of packets per day). We will ensure the code uses efficient parsing (streaming JSON parsing if needed) and vectorized operations for interpolation (e.g. using NumPy) to handle large files quickly.

The output of this stage is a stream of packet records with a unified structure ready to be indexed/stored in the database.

# Scalable Data Storage Options

Storing hundreds of millions of packet records (with time-series characteristics) calls for a database that is scalable, efficient for time-based queries, and flexible with semi-structured data. We considered a few other options:

* Columnar OLAP Database
* Search/Document Database (Elasticsearch)
* NoSQL / Wide-Column Databases
* Time-Series Specialized DBs

But we chose Time-Series Relational Database (SQL) because it is a pragmatic approach is to start with a relational time-series database (Postgres + TimescaleDB) for its familiarity and versatility and SQL is good for complex aggregations and ML data extraction. Using a relational database like PostgreSQL with the TimescaleDB extension is a strong option. TimescaleDB is a PostgreSQL extension optimized for time-series data; it introduces hypertables that automatically partition data by time (and potentially another key, like device ID) for scalability. This allows billions of rows to be handled efficiently while still offering standard SQL for queries. TimescaleDB is known to handle high ingest rates (millions of data points per second) and fast querying for recent and historical data. The advantage here is we can use SQL to filter by any field (time ranges, device addresses, location bounding boxes if we index geospatially, etc.), and join with other tables (for example, a reference table of known device metadata or anomalies). We can store the packet JSON as a JSONB column (for flexibility in storing the full detail), while also extracting key fields into normal columns (timestamp, protocol type, device address, latitude, longitude, signal strength, etc.) for indexing. TimescaleDB also supports compression and retention policies – for instance, compress older data to save space or drop data after X months if we decide not to keep everything indefinitely. As it’s built on PostgreSQL, it benefits from maturity and integration (backup tools, etc.), and if the scale grows, Timescale can be distributed across multiple nodes (via Timescale Forge or multi-node setups). This option provides a good balance between scalability and query expressiveness (full SQL).

The schema will be extensible with a core set of fields common to all protocols (timestamp, protocol type, device identifier, location, signal, etc.) and a blob/JSON for protocol-specific fields. For example, a Bluetooth packet’s JSON will have advertising data that Wi-Fi packets won’t; storing those in a flexible JSON column or separate collection avoids null columns for other protocols. Using Timescale, we shall have separate hypertables for each protocol for clarity (they could still be queried uniformly via a view or by the application logic). Each new protocol module can define what fields to extract and how to store them.

Finally, since all queries are batch/offline, we can afford slightly slower queries as long as they complete (no strict real-time SLA). However, efficient indexing shall be used (time and device fields indexed) so complex anomaly searches complete in a reasonable time for an analyst or for an overnight batch job.

# Machine Learning and Statistical Analysis Tools

With all packet data stored and indexed, the next step is analyzing it to find anomalies, classify device behaviors, and forecast trends. Given the variety of tasks (anomaly detection, classification, forecasting), a flexible Python-based analysis layer will be used, leveraging different libraries for different tasks:

Data Extraction & Preparation: Using Python (pandas and SQL/DB connectors), we can pull subsets of data from the database for analysis. For example, to detect anomalies, we might retrieve a time series of packet counts per minute, or RSSI values over time for a specific device. Pandas can then manipulate and clean this data (handling missing points, filtering out noise, etc.). For classification tasks (e.g., identifying device types from communication patterns), we would gather features per device (like average packet rate, variance of interval, typical signal strength, etc.). This may involve grouping data by device ID and computing summary statistics – which can be done via SQL GROUP BY or in pandas after retrieval. Even though our analysis is batch-mode, we will not use big-data tools (PySpark, Dask).

Anomaly Detection: We will incorporate algorithms to find outliers in the packet data. This can range from simple statistical rules to advanced ML. On the simple end, we might do threshold-based detection (e.g., flag if a device’s packet rate exceeds a threshold compared to its history). More systematically, we can use a library like PyOD (Python Outlier Detection) which is a comprehensive library of anomaly detection algorithms. We could, for instance, use an Isolation Forest to detect anomalies in multi-dimensional data (e.g., a point in feature space defined by [packets_per_minute, avg_packet_size, etc.] that is very different from others).

For time-series specific anomalies (like detecting an abrupt change in a device’s signal pattern over time), we might use specialized time-series anomaly methods. Libraries like Merlion (by Salesforce) provide an integrated framework for time-series anomaly detection and forecasting. Merlion offers a unified API to apply both classic statistical models and deep learning models to detect anomalies in univariate or multivariate time series, and it includes useful post-processing to reduce false alarms. We could feed in a time series (e.g., the count of Bluetooth advertisements per minute for a device) and use Merlion’s default anomaly detector to flag unusual spikes or lulls. The advantage of such frameworks is rapid prototyping: we can try multiple models (even ensembling them) easily.

In some cases, domain knowledge helps define anomalies: for example, Bluetooth LE advertisements are expected at certain intervals (e.g., 20 ms minimal interval for some devices). An anomaly might be a device deviating from the spec – sending too frequently or with irregular gaps. We can encode such rules (which the LLM can be prompted with) or use a statistical approach to see if a device’s advertising interval distribution is bimodal or has outliers. Statistical tests (via SciPy) could check if metrics fall outside expected ranges (like using Z-scores or percentile-based thresholds for things like RSSI, packet error rates, etc.).

Classification of Device Types: We may want to classify or identify the type of device based on its communication patterns or signatures in the data. This is a supervised learning task if we have labels (for instance, we know certain MAC address prefixes are phones vs sensors, or certain behavior patterns correspond to say a fitness tracker vs a thermostat). If labeled data is available, we can train classifiers (scikit-learn’s ensemble methods like Random Forests or gradient boosting, or even neural networks if the pattern is complex). Features for classification might include: average packet rate, typical packet sizes, mobility (did the device move across locations or mostly static?), signal strength profile, etc. These features can be extracted from the database in batch. Scikit-learn would be suitable for many algorithms (decision trees, SVM, etc.), which are easy to train and interpret. If we need more complex pattern recognition (like classifying based on sequence of packet types), we could employ sequence models (e.g., an LSTM or transformer model on packet sequences) using PyTorch or TensorFlow. However, that might be a later extension if needed, as simpler features might suffice initially (especially if combined with domain knowledge like known device signatures). Unsupervised learning can also assist here: using clustering (K-means, DBSCAN) to group devices by behavior might reveal natural categories (which the LLM or an analyst can then label). This could be useful if we don’t have ground truth labels for device type – we let the data form clusters and then interpret them (e.g., one cluster might have devices that broadcast very frequently with low latency – perhaps audio devices; another cluster rarely sends data – maybe sensors, etc.).

Time-Series Forecasting: For forecasting tasks, say predicting future network load or signal trends, we can use both classical forecasting models and modern ones. On the classical side, ARIMA models (from the statsmodels library) or exponential smoothing can forecast based on historical data. For example, forecast the number of Wi-Fi packets in the next hour based on daily patterns. These methods are well-understood for univariate series and can provide confidence intervals. On the modern side, we could use again a library like Merlion or Facebook’s NeuralProphet/Prophet to quickly get forecasting with seasonality. If we want to forecast multivariate patterns (like the expected RSSI given time of day and location), we might need regression or advanced models. Python’s ecosystem has libraries like Kats (from Facebook) or GluonTS (Amazon) for time series, and even deep learning approaches (an LSTM model via Keras/PyTorch). Since forecasting isn’t the primary focus in the prompt, we can plan to implement it as needed for specific metrics – e.g., forecasting how a particular device’s behavior might change, to then detect anomalies as deviations from forecast.

Statistical Analysis: Beyond ML, some analyses may involve statistical testing or summarization. For example, comparing two devices’ behavior might involve a t-test or a non-parametric test if we suspect differences. Or analyzing the distribution of inter-arrival times of packets might involve fitting a distribution (SciPy has many stats routines). We will incorporate these tools as needed in Python. The system might output statistical summaries (means, percentiles, histograms) that the LLM can then reason about or describe.

Python Modules and Libraries: To implement the above, the Python environment will include: pandas and numpy for data manipulation, scikit-learn for general ML algorithms (classification, clustering, basic anomaly detection like isolation forest), pyod for a wide array of anomaly detection algorithms (including latest ones, with a unified API), statsmodels (for ARIMA, statistical tests), possibly pmdarima (for automated ARIMA), and domain-specific libraries like scapy or pyshark if low-level packet crafting/decoding is needed (though Wireshark JSON covers decoding). For deep learning tasks, either PyTorch or TensorFlow can be used; PyTorch is often favored for research prototypes due to its flexibility. If we foresee sequence modeling (like an LSTM autoencoder for anomaly detection in sequences), PyTorch Lightning or similar frameworks can speed development.

We will keep the ML module modular as well – separate scripts or classes for each type of analysis. For instance, an AnomalyDetector class could encapsulate methods to run various anomaly detection algorithms on a given dataset, and an OutputGenerator to produce a human-friendly report of anomalies. This separation means we can plug in new algorithms or adjust parameters without affecting the ingestion or storage layers.

Finally, all analysis will be batch-oriented (as specified). This means we don’t need streaming analytics frameworks; instead, we might run these analyses on a schedule or on-demand. For example, a daily job might run anomaly detection on the past 24 hours of data to flag anything unusual. Another job might recompute classification results weekly as more data comes in. Batch processing also allows the use of the full dataset for training models. If we were to incorporate new protocols like Wi-Fi or 802.15.4, we could develop separate analysis routines for those (since what constitutes an anomaly in Zigbee might differ from Bluetooth). The ML module should therefore be aware of protocol context – e.g., an anomaly detector might need to know the normal range of values for that protocol’s fields (which could be hardcoded or learned from training data).

# LLM-Guided Analysis and Anomaly Hunting

A Large Language Model will be used to guide the analysis. The LLM will act as an intelligent assistant that can both direct the data analysis (by formulating queries or code) and interpret the results in the context of wireless protocols. There are several roles the LLM will play:

Natural Language Interface: Users or engineers can describe what they’re looking for in plain English (or any language). For example: "Find any anomalies in the Bluetooth advertising packets – perhaps devices that aren’t conforming to the Bluetooth spec’s timing or format." The LLM will parse this request and determine an approach to investigate it.

Query/Code Generation: The LLM can translate high-level requests into concrete actions. It might generate an SQL query to retrieve relevant data (if the task is simple filtering/aggregation), or more complex Python code to perform analysis using our ML library. For instance, in the above example, it could generate Python code that groups packets by device and computes the intervals between advertisements, then flags devices with irregular intervals. The LLM shall be able to safely execute generated code against our dataset. This could be done with an environment like Jupyter or a back-end service that the LLM can interact with via an API.

Iterative Analysis (Agent Role): The LLM can function as an agent that iteratively hones in on anomalies. For example, it might start by asking for general statistics (it could prompt something like: “Show me the distribution of advertising intervals for each device”), get the results (perhaps as a plot or data summary), then decide “One device looks unusual with much longer intervals – let's zoom in on that one”, and generate a follow-up query focusing on that device’s data. This agent-like behavior can be facilitated by frameworks such as LangChain, which allows an LLM to use tools (database query tool, Python REPL, etc.) in sequence. By giving the LLM access to a few tools (like a function to run SQL, a function to execute Python and return output, etc.), it can autonomously navigate the data analysis steps. This reduces manual effort and might uncover non-obvious anomalies via the LLM’s reasoning.

Protocol Knowledge and Guidance: The LLM will be prompted with context about the specific wireless protocol standards to guide its search. For Bluetooth, we can provide it with snippets of the Bluetooth spec or known expected behaviors (for example, “Advertising interval is typically 20 ms to 10.24 s; continuous advertising at faster rates might indicate an anomaly”). The LLM’s task is not only to execute brute-force analysis, but also to bring in expert knowledge – essentially acting like a seasoned network analyst. Over time, we can refine these prompts or even fine-tune the LLM on domain data (like logs of known anomalies and normal cases) so that it becomes smarter at identifying what “unusual” means in context. In initial cloud-based tests, we might leverage powerful models (GPT-4 or others) which have seen a lot of technical knowledge and may already “know” some Bluetooth/Wi-Fi details. Eventually, for local deployment, we may fine-tune an open model on documentation from Bluetooth SIG, IEEE, etc., to imbue it with domain expertise.

Summarizing Results: After analysis, the LLM will present a summary in natural language. It might say, for example: “Out of 5 devices observed, 4 followed normal advertisement patterns, but device 1D:8D:38:F9:93:2B exhibited irregular intervals (often 100 ms, exceeding typical maximum of 20 ms) and a consistently weaker signal. This could indicate a misconfigured device or an anomaly.” The summary should reference salient numbers or findings and possibly suggest next steps (the LLM could even recommend checking certain fields or correlating with other data, showing its reasoning). Because the LLM can generate quite comprehensive explanations, this helps translate raw analysis into actionable intelligence for users who may not be data scientists.

Integration Design: Initially, we can use a cloud-based LLM (for example, OpenAI’s GPT-4 via API or similar) to develop the logic. This allows rapid iteration thanks to their advanced capabilities. The LLM can be given a system prompt describing the data schema and available tools, then user prompts as above. We must, however, be cautious with data privacy and size (100 MB of raw data is too large to feed directly in a prompt). The approach will be that the LLM asks for specific slices of data and we feed only those results back (so it's operating on summarized information, not everything at once). This aligns with the typical use of LLMs in analysis: they handle the reasoning and coordination, while heavy data crunching is done by code.

For local deployment, we will integrate an open-source LLM. Meta’s LLaMA 2 or Alibaba’s Qwen are promising candidates, as mentioned. These models are available in sizes (e.g., 7B, 13B, 70B parameters for LLaMA2) that can run on local hardware (with enough GPU or optimized libraries) and have appropriate licenses. In fact, Qwen (latest versions in 2025) is known for strong reasoning and “agentic capabilities for tool use, memory, and autonomous workflows”, which means it’s designed to work with tools and could be well-suited for our agent approach. Both LLaMA2 and Qwen are Apache 2.0 licensed (or similar), meaning we can use them commercially and fine-tune if needed. We might run these via LM Studio, an application that allows running local models like LLaMA or Qwen on a PC with a user-friendly interface. Notably, LM Studio also provides a Python SDK, so our system could interface with a locally running model through that SDK or an API, effectively replacing the cloud API with a local call. This ensures no data leaves the premises and we have full control over the LLM’s operation (and costs). The trade-off is that local models might be slower or slightly less “knowledgeable” than the latest proprietary models, but with fine-tuning and the fact that we can iterate on prompts, they should be effective for our domain.

Example Workflow: To illustrate, suppose the LLM gets an instruction to find anomalies in a day’s Bluetooth data. The conversation (internally) might go like:

The system prompt provides an overview of what data is available (e.g., “You have access to a database of packets with fields: time, device_addr, channel, rssi, etc., and you can ask for computations or run Python.”).

User (or an automated trigger) asks: “Are there any devices behaving oddly according to Bluetooth standards?”

The LLM might generate a plan: first query the number of packets per device, or the advertisement interval distributions. It might produce a small Python snippet using pandas to compute each device’s mean and max advertisement interval.

Our system executes that code on the dataset (since it’s batch, it could load the day’s data into a DataFrame). Suppose it finds one device with an average interval of 100 ms while all others are ~20 ms.

The LLM sees the result and might then say: “Device X has an average interval of 100 ms, which is unusual. Let’s inspect its signal or data content.” It could then query if that device had any error flags or unusual payloads.

After gathering all evidence, the LLM forms a conclusion and describes it, possibly like a mini-report as mentioned earlier.

Throughout this, the modular nature is maintained: the LLM module communicates with the database/analysis module through well-defined interfaces (e.g., a function query_db(sql) or run_analysis(code) that the LLM’s output can be fed into). This prevents the LLM from doing anything outside its scope and allows monitoring. It also means we can upgrade the LLM (swap in a new model, or even have multiple LLMs for different tasks) without changing the core logic of data handling.

# Modular Architecture and Extensibility

The entire system is designed to be modular, meaning each component (ingestion, storage, analysis, LLM interface) can be modified or extended independently. This modularity is crucial as we plan to incorporate additional wireless protocols and possibly new analysis methods over time:

Adding New Protocols: The initial focus is Bluetooth, but the system will accommodate IEEE 802.15.4 (e.g., Zigbee) and Wi-Fi with minimal friction. We can achieve this by abstracting the packet format. For instance, the ingestion module might have a generic interface like parse_packet(packet_json) that returns a normalized record (with common fields and protocol-specific subfields). We can implement protocol-specific parsers: parse_bluetooth(json), parse_802154(json), parse_wifi(json) that handle the differences in JSON structure (Wireshark JSON for Wi-Fi will have fields like “wlan.ssid” or “radiotap.dbm_antsignal” for RSSI, etc., whereas 802.15.4 might have “wpan.src64” for address, etc.). These can all be plugged into the ingestion pipeline based on an identifier in the JSON (the frame.protocols field can tell us which protocols are present in that packet). The GPS linking logic remains the same regardless of protocol. By isolating protocol-specific logic, we ensure that adding a new protocol (or a new version of a protocol) doesn’t require rewriting the whole pipeline – just adding a new parser and maybe adjusting the database schema to include any new fields that are worth indexing.

Swappable Analysis Modules: The machine learning components should be loosely coupled. For instance, if we use PyOD for anomaly detection now, but later find a better library or a custom algorithm, we can replace that without affecting ingestion or storage. We can define clear input/output for each analysis: e.g., an anomaly detection module takes in a dataset (perhaps as a pandas DataFrame or a database table name and time range) and outputs a list of anomalies (with details like which packets or devices are flagged, and why). The LLM can then take that output and explain it. Because the LLM’s interpretation might depend on how results are presented, we’ll keep the result format somewhat consistent (like always include fields [entity, metric, value, reason] for anomalies). This way the LLM prompt can be static even if we change the internal algorithm.

Testing and Maintenance: Modular design aids in testing. Each module can be unit-tested with dummy data. For example, we can test the ingestion on a small JSON capture and a snippet of GPX to ensure timestamps interpolate correctly. We can test that the database insertion handles edge cases (like missing fields). For the ML part, we can simulate a known anomaly in a small dataset and see if the detection module finds it. The LLM module can be tested with sample dialogues and perhaps using a smaller model or a dry-run mode. By ensuring each part works in isolation, the overall system will be more robust when components are integrated.

Performance Considerations: Because modules run in batch, we can allocate resources appropriately. The ingestion might be I/O bound (reading files, writing to DB), so we could parallelize it (e.g., use Python’s multiprocessing or threads to parse JSON in chunks). The database is likely the central resource – we must ensure writes are batched (to avoid per-packet insert overhead; use bulk inserts or COPY for SQL, or bulk API for Elastic). We should also plan for indexing strategies (Timescale automatically indexes time; we might add an index on device address if queries often filter by that). The analysis modules can load data in segments if memory is a concern (processing 100 million rows at once is not feasible on a single machine; but often analysis doesn’t need every row simultaneously – we can do iterative or map-reduce style processing if needed). We shall assume very large-scale ML is not needed, so do not use Spark with its MLlib or use Dask to distribute computations.

User Interaction: Initially, the "user" will just be us (developers) testing via command line or Jupyter notebooks. But if others will use the system, we could consider building a simple interface. For example, a web dashboard that shows recent anomalies or allows entering a query in natural language that the LLM processes. Thanks to the modular backend, exposing a new front-end (web UI, CLI, or even voice interface) is feasible without altering core logic. The LLM’s natural language capability might even serve as a backend for a chatbot interface where an analyst can chat with the system (“Which device had the highest packet loss yesterday?” -> LLM processes and answers). This is an optional extension, but worth noting given the capabilities.

In conclusion, this modular, Python-driven architecture will handle the pipeline from raw packet capture to advanced analysis and LLM-guided insights. We discussed robust database options for scaling to hundreds of millions of records (SQL with time-series extensions, columnar stores for big data analytics, and search indexing for flexible queries), each with proven scalability (e.g., ClickHouse handling billions of events, Timescale leveraging PostgreSQL’s reliability with time-series performance enabling multi-field searches on packet data). The machine learning toolbox will enable a range of analyses – from detecting rare anomalies (using libraries like PyOD or Merlion) to classifying device types and forecasting future behavior – all in batch mode for thorough offline processing. The incorporation of an LLM, whether cloud-based or eventually local (via LLaMA, Qwen, etc. with tools like LM Studio), adds a powerful layer of intelligence, automating the reasoning over data and lowering the barrier to finding insights. By keeping the system modular and extensible, we ensure that new protocols, models, or database technologies can be integrated as the project evolves, future-proofing the design against the fast-changing landscape of data engineering and AI.